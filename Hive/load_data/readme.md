# Варианты скриптов:

1) `create_db.sh` - создаёт базу данных в Hive
2) `fill_table.sh` - создаёт таблицу и заполняет её из файла
3) `create_db_with_table.sh` - объединяет скрипты 1 и 2

## Инструкция к скрипту `create_db.sh`:

### Необходимо запустить скрипт `create_db.sh` со следующими параметрами (слева указаны порядковые номера):

1) Пароль для пользователя hadoop
2) Глобальный IP-адрес JN
3) Имя базы данных

### Пример запуска скрипта:

`sh create_db.sh password_hadoop_strong 176.0.0.1 db_name`

## Инструкция к скрипту `fill_table.sh`:

### Необходимо запустить скрипт `fill_table.sh` со следующими параметрами (слева указаны порядковые номера):

1) Пароль для пользователя hadoop
2) Глобальный IP-адрес JN
3) Имя таблицы (с указание базы данных)
4) Имя файла со скриптом для создания таблицы (очень сложно и часто невозможно корректно извлечь из данных)
5) Имя файла csv с данными

### Пример запуска скрипта:

`sh fill_table.sh password_hadoop_strong 176.0.0.1 db_name.table_name create_table.sh ds.csv`

## Инструкция к скрипту `create_db_with_table.sh`:

### Необходимо запустить скрипт `create_db_with_table.sh` со следующими параметрами (слева указаны порядковые номера):

1) Пароль для пользователя hadoop
2) Глобальный IP-адрес JN
3) Имя базы данных
4) Имя таблицы (с указание базы данных)
5) Имя файла со скриптом для создания таблицы (очень сложно и часто невозможно корректно извлечь из данных)
6) Имя файла csv с данными

### Пример запуска скрипта:

`sh create_db_with_table.sh password_hadoop_strong 176.0.0.1 db_name db_name.table_name create_table.sh ds.csv`

## Примечания:

* Файлы со скриптом для создания таблицы и с данными должны находиться в директории со скриптами, и указываться должно только их имя, без пути
* На кластере предварительно должен быть развёрнуты Hadoop, YARN и Hive, например, способами, описанными в директориях Hadoop, Yarn и Hive этого репозитория соответственно
* На машине, на которой запускаются скрипты должен быть установлен sshpass
* Пароли должны передаваться в виде, воспринимаемом bash, то есть, например, знаки $ должны быть экранированы

# Инструкция по загрузке данных в партиционированную таблицу Hive без скрипта:

## Используемые обозначения:

* `$JN_IP` - глобальный IP-адрес JN
* `$DATA` - имя файла с данными
* `$DB` - имя базы данных
* `$TABLE` - имя таблицы и указанием наименования базы данных, например `mydb.mytable`

## Действия:

1) Предварительно загрузить на кластер файл с данными: `scp $DATA hadoop@$JN_IP:/home/hadoop`

2) Подключиться к edge-ноде по ssh: `ssh hadoop@$JN_IP`

3) Создать (если требуется) на HDFS директорию для размещения файла с данными: `hdfs dfs -mkdir -p /load_data`

4) Загрузить данные на HDFS: `hdfs dfs -put $DATA /load_data`

5) Подключиться к hive: `beeline -u jdbc:hive2://jn:5433 -n scott -p tiger`

6) Создать базу данных, если это требуется: `create database IF NOT EXISTS $DB;`

7) При использовании динамического партиционирования выполнить команды:

* `SET hive.exec.dynamic.partition = true;`
* `SET hive.exec.dynamic.partition.mode = nonstrict;`

8) Создать таблицу с необходимой схемой и параметрами файла, из которого будут загружаться данные, при помощи команды hive `create table $TABLE` во многом аналогичной SQL. При этом, если не используется динамическое партиционирование, необходимо указать столбец, по которому оно производится, например:

        create table if not exists mtdb.mytable (
            c1 string,
            c2 float
        )
        PARTITIONED BY (partition_col int)
        ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
        LINES TERMINATED BY '\n';

9) Загрузить данные в таблицу: `load data inpath '/load_data/$DATA' into table $TABLE;`